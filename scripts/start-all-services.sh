#!/bin/bash
# Script de d√©marrage de tous les services Big Data
# Usage: ./start-all-services.sh

set -e

echo "=========================================="
echo "üöÄ D√âMARRAGE CLUSTER BIG DATA"
echo "=========================================="
echo ""

# Couleurs pour l'affichage
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Fonction pour afficher les messages
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

# V√©rifier que nous sommes dans le conteneur
if [ ! -d "$HADOOP_HOME" ]; then
    echo "‚ùå Erreur: HADOOP_HOME non d√©fini. √ätes-vous dans le conteneur?"
    exit 1
fi

# 1. D√©marrer SSH
log_info "1Ô∏è‚É£  D√©marrage SSH..."
service ssh start
sleep 2

# 2. Formater NameNode si n√©cessaire
if [ ! -d "/opt/hadoop/dfs/name/current" ]; then
    log_info "2Ô∏è‚É£  Formatage NameNode (premi√®re utilisation)..."
    $HADOOP_HOME/bin/hdfs namenode -format -force
else
    log_info "2Ô∏è‚É£  NameNode d√©j√† format√©, on continue..."
fi

# 3. D√©marrer Hadoop HDFS
log_info "3Ô∏è‚É£  D√©marrage Hadoop HDFS..."
$HADOOP_HOME/sbin/start-dfs.sh
sleep 5

# V√©rifier HDFS
if jps | grep -q "NameNode"; then
    log_info "   ‚úÖ NameNode d√©marr√©"
else
    log_warn "   ‚ö†Ô∏è  NameNode non d√©tect√©"
fi

if jps | grep -q "DataNode"; then
    log_info "   ‚úÖ DataNode d√©marr√©"
else
    log_warn "   ‚ö†Ô∏è  DataNode non d√©tect√©"
fi

# 4. D√©marrer YARN
log_info "4Ô∏è‚É£  D√©marrage YARN..."
$HADOOP_HOME/sbin/start-yarn.sh
sleep 5

if jps | grep -q "ResourceManager"; then
    log_info "   ‚úÖ ResourceManager d√©marr√©"
fi

if jps | grep -q "NodeManager"; then
    log_info "   ‚úÖ NodeManager d√©marr√©"
fi

# 5. Cr√©er r√©pertoires HDFS pour Hive
log_info "5Ô∏è‚É£  Cr√©ation r√©pertoires HDFS pour Hive..."
$HADOOP_HOME/bin/hdfs dfs -mkdir -p /tmp
$HADOOP_HOME/bin/hdfs dfs -mkdir -p /user/hive/warehouse
$HADOOP_HOME/bin/hdfs dfs -chmod g+w /tmp
$HADOOP_HOME/bin/hdfs dfs -chmod g+w /user/hive/warehouse
log_info "   ‚úÖ R√©pertoires Hive cr√©√©s"

# 6. D√©marrer HBase
log_info "6Ô∏è‚É£  D√©marrage HBase..."
$HBASE_HOME/bin/start-hbase.sh
sleep 5

if jps | grep -q "HMaster"; then
    log_info "   ‚úÖ HBase Master d√©marr√©"
else
    log_warn "   ‚ö†Ô∏è  HBase Master non d√©tect√©"
fi

# 7. D√©marrer HBase Thrift Server (pour Python)
log_info "7Ô∏è‚É£  D√©marrage HBase Thrift Server..."
$HBASE_HOME/bin/hbase-daemon.sh start thrift
sleep 3
log_info "   ‚úÖ Thrift Server d√©marr√© (port 9090)"

# 8. Initialiser schema Hive (si premi√®re fois)
log_info "8Ô∏è‚É£  Initialisation Metastore Hive..."
if [ ! -d "$HIVE_HOME/metastore_db" ]; then
    cd $HIVE_HOME
    $HIVE_HOME/bin/schematool -dbType derby -initSchema
    log_info "   ‚úÖ Schema Hive initialis√©"
else
    log_info "   ‚úÖ Schema Hive d√©j√† existant"
fi

# 9. D√©marrer Hive Metastore
log_info "9Ô∏è‚É£  D√©marrage Hive Metastore..."
nohup $HIVE_HOME/bin/hive --service metastore > /var/log/hive-metastore.log 2>&1 &
sleep 5
log_info "   ‚úÖ Metastore d√©marr√©"

# 10. D√©marrer HiveServer2
log_info "üîü D√©marrage HiveServer2..."
nohup $HIVE_HOME/bin/hive --service hiveserver2 > /var/log/hive-server2.log 2>&1 &
sleep 5
log_info "   ‚úÖ HiveServer2 d√©marr√© (port 10000)"

# 11. D√©marrer Spark Master
log_info "1Ô∏è‚É£1Ô∏è‚É£  D√©marrage Spark Master..."
$SPARK_HOME/sbin/start-master.sh
sleep 3

if jps | grep -q "Master"; then
    log_info "   ‚úÖ Spark Master d√©marr√© (port 8080)"
fi

# 12. D√©marrer Spark History Server
log_info "1Ô∏è‚É£2Ô∏è‚É£  D√©marrage Spark History Server..."
$SPARK_HOME/sbin/start-history-server.sh
sleep 2
log_info "   ‚úÖ History Server d√©marr√© (port 18080)"

echo ""
echo "=========================================="
echo "‚úÖ TOUS LES SERVICES SONT D√âMARR√âS"
echo "=========================================="
echo ""

# Afficher les services actifs
log_info "Services Java actifs:"
jps

echo ""
log_info "üåê URLs des interfaces Web:"
echo "   Hadoop NameNode:    http://localhost:9870"
echo "   YARN ResourceMgr:   http://localhost:8088"
echo "   Spark Master:       http://localhost:8080"
echo "   Spark History:      http://localhost:18080"
echo "   HBase Master:       http://localhost:16010"
echo ""

log_info "üîå Ports des services:"
echo "   HDFS NameNode:      9000"
echo "   HBase Thrift:       9090"
echo "   HiveServer2:        10000"
echo "   Spark Master:       7077"
echo ""

log_info "üìù Pour tester, ex√©cutez:"
echo "   cd /tests && python3 test_all.py"
echo ""
