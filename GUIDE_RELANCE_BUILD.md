# ğŸ”„ Guide de Relance du Build aprÃ¨s Ã‰chec

## âŒ ProblÃ¨me RencontrÃ©

Le build Docker a plantÃ© Ã  l'Ã©tape 4/35 lors du tÃ©lÃ©chargement de Hadoop :
```
[ 4/35] RUN wget ... hadoop-3.3.6.tar.gz ... 749.6s
```

**Cause** : Timeout rÃ©seau aprÃ¨s 12.5 minutes de tÃ©lÃ©chargement (Hadoop = ~500 MB)

---

## âœ… Solution : Dockerfile v2.0 OptimisÃ©

J'ai crÃ©Ã© une **nouvelle version du Dockerfile** avec :

### ğŸš€ AmÃ©liorations Principales

1. **TÃ©lÃ©chargements Robustes avec Retry**
   ```dockerfile
   wget --retry-connrefused --waitretry=1 --read-timeout=20 --timeout=15 -t 5
   ```
   - `--retry-connrefused` : Retry si connexion refusÃ©e
   - `--waitretry=1` : Attendre 1 seconde entre retries
   - `--read-timeout=20` : Timeout de lecture 20 secondes
   - `--timeout=15` : Timeout de connexion 15 secondes
   - `-t 5` : Maximum 5 tentatives

2. **Messages de Progression**
   ```dockerfile
   echo "TÃ©lÃ©chargement Hadoop..." && \
   wget ... && \
   echo "Extraction Hadoop..." && \
   echo "Hadoop installÃ© avec succÃ¨s"
   ```

3. **Optimisation des Packages**
   ```dockerfile
   apt-get install -y --no-install-recommends
   apt-get clean
   rm -rf /var/lib/apt/lists/*
   ```

4. **Suppression de Jupyter** (non utilisÃ© dans le TP)
   - RÃ©duit le temps d'installation Python de ~170s Ã  ~120s

---

## ğŸ—ï¸ Relancer le Build

### Option 1 : Build Standard (RecommandÃ©)

```powershell
cd C:\Users\Minfo\hadoop-spark-project

# Nettoyer les builds prÃ©cÃ©dents
docker builder prune -f

# Relancer le build avec le nouveau Dockerfile
docker build -t omsefraoui/hadoop-spark-cluster:latest .
```

### Option 2 : Build avec Logs DÃ©taillÃ©s

```powershell
docker build --progress=plain -t omsefraoui/hadoop-spark-cluster:latest . 2>&1 | Tee-Object build.log
```

Cela sauvegarde tous les logs dans `build.log` pour analyse.

### Option 3 : Build avec Cache DÃ©sactivÃ©

Si vous avez des problÃ¨mes de cache :

```powershell
docker build --no-cache -t omsefraoui/hadoop-spark-cluster:latest .
```

âš ï¸ **Attention** : Cette option prendra plus de temps (tout sera refait).

---

## â±ï¸ Temps EstimÃ©s avec Dockerfile v2.0

| Ã‰tape | Ancien | Nouveau | AmÃ©lioration |
|-------|--------|---------|--------------|
| Packages systÃ¨me | 120s | 90s | -25% |
| Python + pip | 170s | 120s | -30% |
| Hadoop | 750s âŒ | 300-400s | -50% + retry |
| Spark | ~500s | 200-300s | -40% + retry |
| Hive | ~300s | 150-200s | -33% + retry |
| HBase | ~250s | 120-150s | -40% + retry |
| Configuration | 60s | 60s | = |
| **TOTAL** | **~35-40 min** | **20-30 min** | **-40%** |

---

## ğŸ” Monitoring du Build

### Voir la Progression en Temps RÃ©el

```powershell
# Dans un autre terminal
docker ps -a
docker logs -f <container_id_du_build>
```

### Points de VÃ©rification

AprÃ¨s chaque grande Ã©tape, vous verrez :
```
âœ“ Hadoop installÃ© avec succÃ¨s
âœ“ Spark installÃ© avec succÃ¨s
âœ“ Hive installÃ© avec succÃ¨s
âœ“ HBase installÃ© avec succÃ¨s
```

---

## ğŸ› Si le Build Ã‰choue Encore

### ProblÃ¨me 1 : Timeout RÃ©seau Persistant

**Solution** : Augmenter les timeouts dans le Dockerfile

```dockerfile
wget --retry-connrefused --waitretry=2 --read-timeout=30 --timeout=20 -t 10
```

### ProblÃ¨me 2 : Miroir Apache Lent

**Solution A** : Utiliser un miroir plus proche

Modifiez les URLs dans le Dockerfile :
```dockerfile
# Essayez un miroir europÃ©en
https://dlcdn.apache.org/hadoop/...
# Ou un miroir US
https://downloads.apache.org/hadoop/...
```

**Solution B** : TÃ©lÃ©charger manuellement

```powershell
# 1. TÃ©lÃ©charger les archives localement
cd C:\Users\Minfo\Downloads

# TÃ©lÃ©charger avec un navigateur ou wget
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
wget https://archive.apache.org/dist/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz
wget https://archive.apache.org/dist/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz
wget https://archive.apache.org/dist/hbase/2.5.5/hbase-2.5.5-bin.tar.gz

# 2. Les placer dans le projet
mkdir C:\Users\Minfo\hadoop-spark-project\downloads
move *.tar.gz C:\Users\Minfo\hadoop-spark-project\downloads\
move *.tgz C:\Users\Minfo\hadoop-spark-project\downloads\

# 3. Modifier le Dockerfile pour utiliser COPY au lieu de wget
```

### ProblÃ¨me 3 : Pas Assez d'Espace Disque

```powershell
# VÃ©rifier l'espace
docker system df

# Nettoyer
docker system prune -a --volumes

# VÃ©rifier Ã  nouveau
docker system df
```

### ProblÃ¨me 4 : MÃ©moire Insuffisante

Docker Desktop â†’ Settings â†’ Resources â†’ Memory â†’ Au moins 8 GB

---

## ğŸ“Š DiffÃ©rences Dockerfile v1.0 vs v2.0

| Feature | v1.0 | v2.0 |
|---------|------|------|
| Retry automatique | âŒ | âœ… |
| Messages de progression | âŒ | âœ… |
| Timeout configurÃ© | âŒ | âœ… |
| Optimisation packages | Partielle | ComplÃ¨te |
| Jupyter inclus | âœ… | âŒ (non utilisÃ©) |
| Nettoyage cache apt | Partiel | Complet |
| Gestion erreurs | Basique | AvancÃ©e |

---

## ğŸ¯ Checklist PrÃ©-Build

Avant de relancer le build, vÃ©rifiez :

- [ ] Docker Desktop est dÃ©marrÃ©
- [ ] Au moins 8 GB RAM allouÃ©s Ã  Docker
- [ ] Au moins 30 GB d'espace disque libre
- [ ] Connexion internet stable (vÃ©rifiez votre vitesse)
- [ ] Pas d'autres builds Docker en cours
- [ ] Les 5 scripts Python sont dans `scripts/`
- [ ] Les 4 fichiers de donnÃ©es sont dans `data/`
- [ ] Les configurations sont dans `config/`

**VÃ©rification rapide** :
```powershell
cd C:\Users\Minfo\hadoop-spark-project
dir scripts\  # Doit afficher 5 fichiers .py
dir data\     # Doit afficher 4 fichiers
dir config\   # Doit afficher 4 sous-dossiers
```

---

## âœ… Commande de Build Finale

```powershell
cd C:\Users\Minfo\hadoop-spark-project

# Nettoyer
docker builder prune -f

# Builder avec logs
docker build -t omsefraoui/hadoop-spark-cluster:latest . 2>&1 | Tee-Object build.log

# En cas de succÃ¨s
echo "Build rÃ©ussi ! Tester avec : docker-compose up -d"
```

---

## ğŸ“ˆ Suivi de la Progression

Le build passera par ces Ã©tapes :

```
[ 1/35] FROM ubuntu:20.04
[ 2/35] RUN apt-get update && apt-get install...
[ 3/35] RUN pip3 install...
[ 4/35] RUN wget ... hadoop... â† Ã‰tape critique
[ 5/35] RUN wget ... spark...  â† Ã‰tape critique
[ 6/35] RUN wget ... hive...   â† Ã‰tape critique
[ 7/35] RUN wget ... hbase...  â† Ã‰tape critique
...
[35/35] CMD ["/bin/bash"]
```

**Si vous voyez "installÃ© avec succÃ¨s"** aprÃ¨s chaque tÃ©lÃ©chargement, tout va bien !

---

## ğŸš¨ En Cas d'Ã‰chec RÃ©pÃ©tÃ©

Si le build Ã©choue plusieurs fois au mÃªme endroit :

1. **VÃ©rifiez votre connexion internet**
   ```powershell
   Test-Connection archive.apache.org
   ```

2. **Essayez Ã  un autre moment**
   - Les miroirs Apache peuvent Ãªtre surchargÃ©s
   - Essayez le soir ou le week-end

3. **Utilisez un VPN** (si disponible)
   - Peut aider Ã  contourner les limitations rÃ©seau

4. **Option de secours** : Build par Ã©tapes
   - CrÃ©ez plusieurs Dockerfiles intermÃ©diaires
   - Buildez Ã©tape par Ã©tape

---

## ğŸ’¡ Conseils Pratiques

1. **Lancez le build le soir**
   - Laissez tourner toute la nuit
   - Les miroirs Apache sont moins chargÃ©s

2. **Fermez les applications gourmandes**
   - Navigateurs avec beaucoup d'onglets
   - IDEs lourds
   - Logiciels de streaming

3. **Utilisez une connexion filaire** (pas WiFi)
   - Plus stable pour les gros tÃ©lÃ©chargements

4. **Ne touchez pas Ã  l'ordinateur pendant le build**
   - Ã‰vitez de mettre en veille
   - Ne fermez pas Docker Desktop

---

## ğŸ‰ AprÃ¨s un Build RÃ©ussi

```powershell
# 1. VÃ©rifier l'image
docker images omsefraoui/hadoop-spark-cluster

# 2. Tester rapidement
docker run -it --rm omsefraoui/hadoop-spark-cluster:latest hadoop version

# 3. Tester avec docker-compose
docker-compose up -d
timeout /t 180
docker ps
# Ouvrir http://localhost:8080

# 4. ArrÃªter
docker-compose down

# 5. Publier
docker login
docker push omsefraoui/hadoop-spark-cluster:latest
```

---

## ğŸ“ Support

Si vous rencontrez toujours des problÃ¨mes :

1. Sauvegardez les logs : `build.log`
2. VÃ©rifiez l'Ã©tape exacte d'Ã©chec
3. Consultez les solutions dans ce guide
4. Essayez les options alternatives

---

**Bon courage pour le build ! ğŸš€**

**Note** : Le Dockerfile v2.0 est plus robuste et devrait rÃ©ussir. Si Ã©chec, c'est probablement un problÃ¨me de connexion internet temporaire.
