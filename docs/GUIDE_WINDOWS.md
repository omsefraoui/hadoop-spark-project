# üöÄ Guide Windows - Hadoop Spark Cluster

## üìã Pr√©requis

- ‚úÖ Docker Desktop install√© et d√©marr√©
- ‚úÖ WSL 2 activ√© (recommand√©)
- ‚úÖ Au moins 8 GB RAM disponibles

## üèóÔ∏è 1. Construction de l'image Docker

### M√©thode 1: Build simple
```powershell
cd C:\Users\Minfo\hadoop-spark-project
docker build -t omsefraoui/hadoop-spark-cluster:latest .
```

### M√©thode 2: Build avec cache (recommand√© pour d√©veloppement)
```powershell
# Activer BuildKit
$env:DOCKER_BUILDKIT=1

# Build avec cache
docker build `
  --cache-from omsefraoui/hadoop-spark-cluster:latest `
  -t omsefraoui/hadoop-spark-cluster:latest .
```

### M√©thode 3: Build script PowerShell (automatis√©)
```powershell
.\build.ps1
```

## üê≥ 2. Lancement du conteneur

### Option A: Lancement simple
```powershell
docker run -it --name hadoop-cluster `
  -p 9870:9870 `
  -p 8088:8088 `
  -p 18080:18080 `
  -p 16010:16010 `
  -p 10000:10000 `
  -p 4040:4040 `
  omsefraoui/hadoop-spark-cluster:latest
```

### Option B: Avec docker-compose (recommand√©)
```powershell
docker-compose up -d
```

## ‚è≥ 3. V√©rifier que les services d√©marrent

Les services prennent **2-3 minutes** pour d√©marrer. Attendez avant de tester.

### V√©rifier les logs
```powershell
docker logs -f hadoop-cluster
```

Attendez de voir ces messages :
```
>>> Starting HDFS
>>> Starting YARN
>>> Starting HBase
>>> Starting Hive Metastore & HiveServer2
>>> Starting Spark History Server
>>> Services running:
```

### Acc√©der aux interfaces Web (depuis Windows)
Ouvrez votre navigateur :
- **HDFS NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **Spark History**: http://localhost:18080
- **HBase Master**: http://localhost:16010

## üß™ 4. Ex√©cuter les tests Python

### Se connecter au conteneur
```powershell
docker exec -it hadoop-cluster bash
```

### Dans le conteneur, lancer les tests

#### Test complet (tous les services)
```bash
cd /tests
python3 test_all.py
```

#### Tests individuels
```bash
# Test Spark uniquement
python3 test_spark.py

# Test HBase uniquement
python3 test_hbase.py

# Test Hive uniquement
python3 test_hive.py
```

## üìä 5. Exemples d'utilisation

### Spark - Traitement de donn√©es
```bash
cd /scripts
python3 spark_sql.py          # Requ√™tes SQL
python3 spark_joins.py        # Jointures
python3 spark_hbase.py       # Int√©gration Spark + HBase
python3 spark_hive.py        # Int√©gration Spark + Hive
```

### HBase - NoSQL columnar
```bash
# Shell HBase interactif
hbase shell

# Dans le shell HBase:
create 'test_table', 'cf'
put 'test_table', 'row1', 'cf:name', 'Alice'
scan 'test_table'
```

### Hive - Data Warehouse
```bash
# Beeline (client Hive)
beeline -u "jdbc:hive2://localhost:10000"

# Dans Beeline:
SHOW DATABASES;
CREATE TABLE test (id INT, name STRING);
INSERT INTO test VALUES (1, 'Alice');
SELECT * FROM test;
```

## üõ†Ô∏è 6. D√©pannage Windows

### Probl√®me: Port d√©j√† utilis√©
```powershell
# Trouver le processus utilisant un port
netstat -ano | findstr :9870

# Arr√™ter le processus (remplacer PID)
taskkill /PID <PID> /F
```

### Probl√®me: Conteneur ne d√©marre pas
```powershell
# Voir les logs
docker logs hadoop-cluster

# Red√©marrer avec logs en temps r√©el
docker restart hadoop-cluster && docker logs -f hadoop-cluster
```

### Probl√®me: Services lents √† d√©marrer
```powershell
# Attendre 3-5 minutes apr√®s le d√©marrage
# V√©rifier la m√©moire disponible
docker stats hadoop-cluster
```

### Probl√®me: Tests Python √©chouent
```bash
# Dans le conteneur, v√©rifier les services
jps  # Doit montrer: NameNode, DataNode, ResourceManager, etc.

# V√©rifier HDFS
hdfs dfs -ls /

# V√©rifier HBase
echo "status" | hbase shell
```

## üóëÔ∏è 7. Nettoyage

### Arr√™ter le conteneur
```powershell
docker stop hadoop-cluster
```

### Supprimer le conteneur
```powershell
docker rm hadoop-cluster
```

### Supprimer l'image
```powershell
docker rmi omsefraoui/hadoop-spark-cluster:latest
```

### Nettoyage complet Docker
```powershell
# Attention: supprime TOUT ce qui n'est pas utilis√©
docker system prune -a --volumes
```

## üì§ 8. Publication sur DockerHub

### Se connecter √† DockerHub
```powershell
docker login
# Entrez: omsefraoui
# Mot de passe: votre_token
```

### Publier l'image
```powershell
docker push omsefraoui/hadoop-spark-cluster:latest
```

### Taguer une version sp√©cifique
```powershell
docker tag omsefraoui/hadoop-spark-cluster:latest omsefraoui/hadoop-spark-cluster:v1.0
docker push omsefraoui/hadoop-spark-cluster:v1.0
```

## üéì 9. Pour les √©tudiants

### T√©l√©charger l'image d√©j√† construite
```powershell
# Pas besoin de builder, t√©l√©chargez directement
docker pull omsefraoui/hadoop-spark-cluster:latest

# Lancer
docker run -it --name hadoop-tp `
  -p 9870:9870 -p 8088:8088 -p 18080:18080 `
  -p 16010:16010 -p 10000:10000 `
  omsefraoui/hadoop-spark-cluster:latest
```

### Workflow TP classique
1. **D√©marrer** le conteneur
2. **Attendre 3 minutes** que les services d√©marrent
3. **Tester les interfaces Web**
4. **Ex√©cuter** `python3 /tests/test_all.py`
5. **Faire** vos exercices dans `/scripts`
6. **Arr√™ter** proprement avec `Ctrl+C` puis `docker stop hadoop-tp`

## üìû Support

- **Documentation**: Voir `/docs` dans le conteneur
- **Logs**: `docker logs -f hadoop-cluster`
- **Issues**: https://github.com/omsefraoui/hadoop-spark-project

---
**Auteur**: Omar Sefraoui - ENSAO  
**Version**: 1.0  
**Date**: 2025
